{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "def record_audio():\n",
    "    CHUNK = 2048  # Number of audio frames per buffer\n",
    "    FORMAT = pyaudio.paInt16  # Format for audio input\n",
    "    CHANNELS = 1  # Mono\n",
    "    RATE = 16000  # Sampling rate\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    return stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "def transcribe_audio_whisper(stream):\n",
    "    model = whisper.load_model(\"base\")  # Load Whisper model\n",
    "    audio_data = b\"\"\n",
    "\n",
    "    while True:\n",
    "        data = stream.read(1024)\n",
    "        audio_data += data\n",
    "\n",
    "        # Transcribe when audio reaches a certain size\n",
    "        if len(audio_data) > RATE * 5:  # 5 seconds of audio\n",
    "            result = model.transcribe(audio_data)\n",
    "            print(result[\"Recorded\"])\n",
    "            audio_data = b\"\"  # Reset the buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "\n",
    "def transcribe_audio_google(stream):\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "    streaming_config = speech.StreamingRecognitionConfig(config=config)\n",
    "\n",
    "    audio_generator = (stream.read(1024) for _ in range(0, int(RATE / 1024)))\n",
    "    requests = (speech.StreamingRecognizeRequest(audio_content=chunk) for chunk in audio_generator)\n",
    "\n",
    "    responses = client.streaming_recognize(streaming_config, requests)\n",
    "    for response in responses:\n",
    "        for result in response.results:\n",
    "            print(\"Transcript:\", result.alternatives[0].transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9 (audio_callback):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "Exception in thread Thread-10 (transcription_worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/q3/p5td8yjd4zl74d8v3hztzpwh0000gn/T/ipykernel_42642/3530458797.py\", line 8, in audio_callback\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1012, in run\n",
      "NameError: name 'CHUNK' is not defined\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/q3/p5td8yjd4zl74d8v3hztzpwh0000gn/T/ipykernel_42642/3530458797.py\", line 16, in transcription_worker\n",
      "NameError: name 'RATE' is not defined\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import threading\n",
    "\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "def audio_callback(stream):\n",
    "    while True:\n",
    "        data = stream.read(CHUNK)\n",
    "        audio_queue.put(data)\n",
    "\n",
    "def transcription_worker():\n",
    "    audio_buffer = b\"\"\n",
    "    while True:\n",
    "        if not audio_queue.empty():\n",
    "            audio_buffer += audio_queue.get()\n",
    "        if len(audio_buffer) >= RATE * 5:  # 5 seconds of audio\n",
    "            # Transcribe and reset the buffer\n",
    "            result = model.transcribe(audio_buffer)\n",
    "            print(result[\"text\"])\n",
    "            audio_buffer = b\"\"\n",
    "\n",
    "# Run audio processing and transcription in parallel\n",
    "threading.Thread(target=audio_callback, args=(stream,)).start()\n",
    "threading.Thread(target=transcription_worker).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -9981] Input overflowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m stream \u001b[38;5;241m=\u001b[39m record_audio()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# For Whisper:\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m transcribe_audio_whisper(stream)\n",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m, in \u001b[0;36mtranscribe_audio_whisper\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m      5\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m      9\u001b[0m     audio_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Transcribe when audio reaches a certain size\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mread_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, num_frames,\n\u001b[1;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -9981] Input overflowed"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stream = record_audio()\n",
    "\n",
    "    # For Whisper:\n",
    "    transcribe_audio_whisper(stream)\n",
    "\n",
    "    # For Google Speech-to-Text:\n",
    "    # transcribe_audio_google(stream)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
